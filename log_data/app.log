2025-08-25 20:13:33,740 | INFO | cloud_migration | Uploaded parquet_data\logs_20250826_011329.parquet to S3 at archived_data/logs_20250826_011329.parquet
2025-08-25 20:13:33,742 | INFO | cloud_migration | Uploaded parquet_data\monitoring_20250826_011329.parquet to S3 at archived_data/monitoring_20250826_011329.parquet
2025-08-25 20:13:33,744 | INFO | cloud_migration | Uploaded parquet_data\proc_diagnostics_20250826_011329.parquet to S3 at archived_data/proc_diagnostics_20250826_011329.parquet
2025-08-25 20:13:33,746 | INFO | cloud_migration | Uploaded parquet_data\ticks_20250826_011329.parquet to S3 at archived_data/ticks_20250826_011329.parquet
2025-08-25 20:13:33,749 | INFO | cloud_migration | Uploaded parquet_data\uptime_20250826_011329.parquet to S3 at archived_data/uptime_20250826_011329.parquet
2025-08-25 20:13:33,751 | INFO | cloud_migration | Uploaded parquet_data\ws_diagnostics_20250826_011329.parquet to S3 at archived_data/ws_diagnostics_20250826_011329.parquet
2025-08-25 20:13:33,978 | INFO | kafka_consumer | Inserted 4 rows.
2025-08-25 20:13:34,990 | INFO | kafka_consumer | Inserted 175 rows.
2025-08-25 20:13:35,990 | INFO | kafka_consumer | Inserted 166 rows.
2025-08-25 20:13:36,150 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:13:36,492 | INFO | monitoring | Inserted ticks monitoring data for 441 messages.
2025-08-25 20:13:37,032 | INFO | kafka_consumer | Inserted 8 rows.
2025-08-25 20:13:37,603 | WARNING | kafka.producer.record_accumulator | Failed to produce messages to topic-partition TopicPartition(topic='price_ticks', partition=0) with base offset -1: KafkaTimeoutError: Expiring 1 record(s) for TopicPartition(topic='price_ticks', partition=0): 120001 ms has passed since batch creation
2025-08-25 20:13:38,005 | INFO | kafka_consumer | Inserted 96 rows.
2025-08-25 20:13:38,976 | INFO | kafka_consumer | Inserted 122 rows.
2025-08-25 20:13:40,018 | INFO | kafka_consumer | Inserted 6 rows.
2025-08-25 20:13:41,017 | INFO | kafka_consumer | Inserted 68 rows.
2025-08-25 20:13:41,448 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:13:41,924 | INFO | monitoring | Inserted ticks monitoring data for 300 messages.
2025-08-25 20:13:42,011 | INFO | kafka_consumer | Inserted 32 rows.
2025-08-25 20:13:43,015 | INFO | kafka_consumer | Inserted 147 rows.
2025-08-25 20:13:43,993 | INFO | kafka_consumer | Inserted 125 rows.
2025-08-25 20:13:45,020 | INFO | kafka_consumer | Inserted 119 rows.
2025-08-25 20:13:46,005 | INFO | kafka_consumer | Inserted 63 rows.
2025-08-25 20:13:46,636 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:13:47,020 | INFO | kafka_consumer | Inserted 144 rows.
2025-08-25 20:13:47,321 | INFO | monitoring | Inserted ticks monitoring data for 486 messages.
2025-08-25 20:13:48,001 | INFO | kafka_consumer | Inserted 92 rows.
2025-08-25 20:13:49,010 | INFO | kafka_consumer | Inserted 260 rows.
2025-08-25 20:13:50,026 | INFO | kafka_consumer | Inserted 73 rows.
2025-08-25 20:13:51,049 | INFO | kafka_consumer | Inserted 11 rows.
2025-08-25 20:13:51,948 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:13:52,041 | INFO | kafka_consumer | Inserted 77 rows.
2025-08-25 20:13:52,177 | INFO | kafka_consumer | Inserted 300 rows.
2025-08-25 20:13:52,772 | INFO | monitoring | Inserted ticks monitoring data for 813 messages.
2025-08-25 20:13:53,080 | INFO | kafka_consumer | Inserted 9 rows.
2025-08-25 20:13:54,042 | INFO | kafka_consumer | Inserted 267 rows.
2025-08-25 20:13:55,056 | INFO | kafka_consumer | Inserted 32 rows.
2025-08-25 20:13:56,065 | INFO | kafka_consumer | Inserted 55 rows.
2025-08-25 20:13:57,060 | INFO | kafka_consumer | Inserted 68 rows.
2025-08-25 20:13:57,230 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:13:58,074 | INFO | kafka_consumer | Inserted 45 rows.
2025-08-25 20:13:58,192 | INFO | monitoring | Inserted ticks monitoring data for 431 messages.
2025-08-25 20:13:59,044 | INFO | kafka_consumer | Inserted 66 rows.
2025-08-25 20:14:00,058 | INFO | kafka_consumer | Inserted 70 rows.
2025-08-25 20:14:01,040 | INFO | kafka_consumer | Inserted 28 rows.
2025-08-25 20:14:02,075 | INFO | kafka_consumer | Inserted 3 rows.
2025-08-25 20:14:02,388 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:14:03,064 | INFO | kafka_consumer | Inserted 140 rows.
2025-08-25 20:14:03,647 | INFO | monitoring | Inserted ticks monitoring data for 307 messages.
2025-08-25 20:14:04,053 | INFO | kafka_consumer | Inserted 127 rows.
2025-08-25 20:14:05,048 | INFO | kafka_consumer | Inserted 36 rows.
2025-08-25 20:14:06,062 | INFO | kafka_consumer | Inserted 46 rows.
2025-08-25 20:14:06,966 | ERROR | kafka.producer.sender | <Sender client_id=kafka-python-producer-1 transactional_id=None>: Uncaught error in kafka producer I/O thread
Traceback (most recent call last):
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\sender.py", line 110, in run
    self.run_once()
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\sender.py", line 171, in run_once
    poll_timeout_ms = self._send_producer_data()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\sender.py", line 204, in _send_producer_data
    heapq.heappush(queue, item)
TypeError: '<' not supported between instances of 'ProducerBatch' and 'ProducerBatch'
2025-08-25 20:14:07,062 | INFO | kafka_consumer | Inserted 4 rows.
2025-08-25 20:14:07,571 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:14:08,068 | INFO | kafka_consumer | Inserted 162 rows.
2025-08-25 20:14:09,017 | INFO | kafka_consumer | Inserted 40 rows.
2025-08-25 20:14:09,078 | INFO | monitoring | Inserted ticks monitoring data for 375 messages.
2025-08-25 20:14:10,068 | INFO | kafka_consumer | Inserted 4 rows.
2025-08-25 20:14:11,066 | INFO | kafka_consumer | Inserted 170 rows.
2025-08-25 20:14:12,073 | INFO | kafka_consumer | Inserted 58 rows.
2025-08-25 20:14:12,764 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:14:13,081 | INFO | kafka_consumer | Inserted 49 rows.
2025-08-25 20:14:14,071 | INFO | kafka_consumer | Inserted 97 rows.
2025-08-25 20:14:14,471 | INFO | monitoring | Inserted ticks monitoring data for 281 messages.
2025-08-25 20:14:15,084 | INFO | kafka_consumer | Inserted 2 rows.
2025-08-25 20:14:16,081 | INFO | kafka_consumer | Inserted 8 rows.
2025-08-25 20:14:17,063 | INFO | kafka_consumer | Inserted 68 rows.
2025-08-25 20:14:17,936 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:14:18,067 | INFO | kafka_consumer | Inserted 45 rows.
2025-08-25 20:14:19,066 | INFO | kafka_consumer | Inserted 2 rows.
2025-08-25 20:14:19,841 | INFO | monitoring | Inserted ticks monitoring data for 125 messages.
2025-08-25 20:14:20,095 | INFO | kafka_consumer | Inserted 12 rows.
2025-08-25 20:14:21,095 | INFO | kafka_consumer | Inserted 83 rows.
2025-08-25 20:14:22,054 | INFO | kafka_consumer | Inserted 160 rows.
2025-08-25 20:14:23,029 | INFO | kafka_consumer | Inserted 19 rows.
2025-08-25 20:14:23,214 | INFO | monitoring | Completed a monitoring cycle.
2025-08-25 20:14:24,073 | INFO | kafka_consumer | Inserted 9 rows.
2025-08-25 20:14:24,276 | INFO | __main__ | Stopping application via KeyboardInterrupt.
2025-08-25 20:14:24,443 | INFO | kafka_producer | Shutting down producer.
2025-08-25 20:14:24,490 | INFO | kafka_producer | WebSocket closed: code=None msg=None
2025-08-25 20:14:24,701 | INFO | kafka_consumer | Inserted final 2 rows.
2025-08-25 20:14:24,704 | INFO | kafka_consumer | Closing consumer.
2025-08-25 20:14:24,720 | INFO | kafka.coordinator | Stopping heartbeat thread
2025-08-25 20:14:26,522 | ERROR | kafka_producer | Error flushing producer during shutdown
Traceback (most recent call last):
  File "C:\Users\erict\GitRepositories\001 - Projects\02 Project 2\kafka_producer.py", line 76, in start_producer
    func()
  File "C:\Users\erict\GitRepositories\001 - Projects\02 Project 2\kafka_producer.py", line 72, in <lambda>
    ("flushing producer", lambda: producer.flush(timeout=2)),
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\kafka.py", line 919, in flush
    self._accumulator.await_flush_completion(timeout=timeout)
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\record_accumulator.py", line 583, in await_flush_completion
    raise Errors.KafkaTimeoutError('Timeout waiting for future')
kafka.errors.KafkaTimeoutError: KafkaTimeoutError: Timeout waiting for future
2025-08-25 20:14:26,540 | INFO | kafka.producer.kafka | <KafkaProducer client_id=kafka-python-producer-1 transactional_id=None>: Closing the Kafka producer with 2 secs timeout.
2025-08-25 20:14:27,723 | WARNING | kafka.coordinator | Heartbeat thread did not fully terminate during close
2025-08-25 20:14:27,724 | INFO | kafka.coordinator | Leaving consumer group (ticks_ingestor).
2025-08-25 20:14:27,809 | INFO | kafka.conn | <BrokerConnection client_id=kafka-python-2.2.4, node_id=1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2025-08-25 20:14:27,816 | INFO | kafka.conn | <BrokerConnection client_id=kafka-python-2.2.4, node_id=coordinator-1 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
2025-08-25 20:14:27,824 | INFO | __main__ | System shutdown complete.
2025-08-25 20:14:28,559 | ERROR | kafka_producer | Error closing producer during shutdown
Traceback (most recent call last):
  File "C:\Users\erict\GitRepositories\001 - Projects\02 Project 2\kafka_producer.py", line 76, in start_producer
    func()
  File "C:\Users\erict\GitRepositories\001 - Projects\02 Project 2\kafka_producer.py", line 73, in <lambda>
    ("closing producer", lambda: producer.close(timeout=2)),
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\kafka.py", line 630, in close
    self.flush(timeout)
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\kafka.py", line 919, in flush
    self._accumulator.await_flush_completion(timeout=timeout)
  File "C:\Users\erict\anaconda3\Lib\site-packages\kafka\producer\record_accumulator.py", line 583, in await_flush_completion
    raise Errors.KafkaTimeoutError('Timeout waiting for future')
kafka.errors.KafkaTimeoutError: KafkaTimeoutError: Timeout waiting for future
